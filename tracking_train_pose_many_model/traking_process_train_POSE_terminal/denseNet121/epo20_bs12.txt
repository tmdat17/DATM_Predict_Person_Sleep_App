
E:\CTU\LUAN_VAN_2023>python train_pose_denseNet121_beta.py
[['./data_cropped/at_home/lie/lie_wake_967.jpg', 0], ['./data_cropped/at_home/sit/sit_2464.jpg', 1], ['./data_cropped/at_home/stand/stand_976.jpg', 2], ['./data_cropped/at_home/minus/item_2451.jpg', 3], ['./data_cropped/at_home/lie/lie_wake_1356.jpg', 0], ['./data_cropped/at_home/sit/sit_2417.jpg', 1], ['./data_cropped/at_home/stand/stand_804.jpg', 2], ['./data_cropped/at_home/minus/item_298.jpg', 3], ['./data_cropped/at_home/lie/lie_wake_1955.jpg', 0], ['./data_cropped/at_home/lie/lie_wake_655.jpg', 0]]
Chuan bi doc anh tu folder:
scale raw pixel / 255.0
train test split
trainX shape:  (6464, 128, 128, 3)
testX shape:  (2020, 128, 128, 3)
trainY shape:  (6464, 4)
testY shape:  (2020,)
valX shape:  (1616, 128, 128, 3)
valY shape:  (1616, 4)
[INFO] compiling model...
Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5
29084464/29084464 [==============================] - 28s 1us/step
Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #
=================================================================
 densenet121 (Functional)    (None, 4, 4, 1024)        7037504

 global_average_pooling2d (G  (None, 1024)             0
 lobalAveragePooling2D)

 dropout (Dropout)           (None, 1024)              0

 flatten (Flatten)           (None, 1024)              0

 dense (Dense)               (None, 4)                 4100

=================================================================
Total params: 7,041,604
Trainable params: 4,100
Non-trainable params: 7,037,504
_________________________________________________________________
None
bat dau fit model DenseNet121
2023-11-05 14:30:27.362114: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1270874112 exceeds 10% of free system memory.
Epoch 1/20
539/539 [==============================] - 58s 89ms/step - loss: 0.2829 - accuracy: 0.9104 - val_loss: 0.0124 - val_accuracy: 0.9957
Epoch 2/20
539/539 [==============================] - 44s 81ms/step - loss: 0.0362 - accuracy: 0.9882 - val_loss: 0.0058 - val_accuracy: 0.9975
Epoch 3/20
539/539 [==============================] - 44s 81ms/step - loss: 0.0241 - accuracy: 0.9946 - val_loss: 0.0043 - val_accuracy: 0.9988
Epoch 4/20
539/539 [==============================] - 44s 81ms/step - loss: 0.0197 - accuracy: 0.9950 - val_loss: 0.0035 - val_accuracy: 0.9988
Epoch 5/20
539/539 [==============================] - 45s 84ms/step - loss: 0.0167 - accuracy: 0.9955 - val_loss: 0.0030 - val_accuracy: 0.9988
Epoch 6/20
539/539 [==============================] - 44s 82ms/step - loss: 0.0160 - accuracy: 0.9950 - val_loss: 0.0040 - val_accuracy: 0.9994
Epoch 7/20
539/539 [==============================] - 44s 81ms/step - loss: 0.0119 - accuracy: 0.9968 - val_loss: 0.0022 - val_accuracy: 0.9994
Epoch 8/20
539/539 [==============================] - 44s 82ms/step - loss: 0.0140 - accuracy: 0.9960 - val_loss: 0.0015 - val_accuracy: 1.0000
Epoch 9/20
539/539 [==============================] - 44s 82ms/step - loss: 0.0130 - accuracy: 0.9954 - val_loss: 0.0021 - val_accuracy: 1.0000
Epoch 10/20
539/539 [==============================] - 44s 82ms/step - loss: 0.0115 - accuracy: 0.9966 - val_loss: 0.0020 - val_accuracy: 1.0000
Epoch 11/20
539/539 [==============================] - 44s 82ms/step - loss: 0.0124 - accuracy: 0.9964 - val_loss: 0.0011 - val_accuracy: 0.9994
Epoch 12/20
539/539 [==============================] - 44s 82ms/step - loss: 0.0126 - accuracy: 0.9966 - val_loss: 0.0012 - val_accuracy: 0.9994
Epoch 13/20
539/539 [==============================] - 44s 82ms/step - loss: 0.0087 - accuracy: 0.9980 - val_loss: 9.7328e-04 - val_accuracy: 1.0000
Epoch 14/20
539/539 [==============================] - 44s 82ms/step - loss: 0.0103 - accuracy: 0.9972 - val_loss: 0.0010 - val_accuracy: 1.0000
Epoch 15/20
539/539 [==============================] - 44s 82ms/step - loss: 0.0082 - accuracy: 0.9975 - val_loss: 0.0012 - val_accuracy: 1.0000
Epoch 16/20
539/539 [==============================] - 44s 82ms/step - loss: 0.0111 - accuracy: 0.9963 - val_loss: 0.0012 - val_accuracy: 1.0000
Epoch 17/20
539/539 [==============================] - 44s 82ms/step - loss: 0.0106 - accuracy: 0.9972 - val_loss: 5.5964e-04 - val_accuracy: 1.0000
Epoch 18/20
539/539 [==============================] - 44s 82ms/step - loss: 0.0091 - accuracy: 0.9972 - val_loss: 8.9623e-04 - val_accuracy: 1.0000
Epoch 19/20
539/539 [==============================] - 44s 82ms/step - loss: 0.0107 - accuracy: 0.9966 - val_loss: 8.2642e-04 - val_accuracy: 1.0000
Epoch 20/20
539/539 [==============================] - 45s 83ms/step - loss: 0.0083 - accuracy: 0.9968 - val_loss: 0.0012 - val_accuracy: 1.0000
new_model:   <keras.engine.sequential.Sequential object at 0x000002B74AC825E0>
prepare save new_model:
bat dau kiem tra model:
2023-11-05 14:45:35.961279: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.21GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.
63/64 [============================>.] - ETA: 0s2023-11-05 14:45:43.281650: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.15GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.
64/64 [==============================] - 11s 116ms/step
E:\CTU\LUAN_VAN_2023\train_pose_denseNet121_beta.py:154: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels([''] + categories)
E:\CTU\LUAN_VAN_2023\train_pose_denseNet121_beta.py:155: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels([''] + categories)
Accuracy : 100.00%


Recall :100.00%


Precision : 100.00%


F1 : 100.00%


Time train DenseNet121:  14.95

E:\CTU\LUAN_VAN_2023>
