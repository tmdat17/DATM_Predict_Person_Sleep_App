
E:\CTU\LUAN_VAN_2023>python train_pose_mobileNet_beta.py
[['./data_cropped/at_home/sit/sit_1881.jpg', 1], ['./data_cropped/at_home/sit/sit_1511.jpg', 1], ['./data_cropped/at_home/minus/item_2214.jpg', 3], ['./data_cropped/at_home/stand/stand_115.jpg', 2], ['./data_cropped/at_home/lie/lie_wake_1781.jpg', 0], ['./data_cropped/at_home/lie/lie_wake_885.jpg', 0], ['./data_cropped/at_home/lie/lie_wake_1865.jpg', 0], ['./data_cropped/at_home/minus/item_1148.jpg', 3], ['./data_cropped/at_home/minus/item_2227.jpg', 3], ['./data_cropped/at_home/lie/lie_wake_6.jpg', 0]]
Chuan bi doc anh tu folder:
scale raw pixel / 255.0
train test split
trainX shape:  (6464, 128, 128, 3)
testX shape:  (2020, 128, 128, 3)
trainY shape:  (6464, 4)
testY shape:  (2020,)
valX shape:  (1616, 128, 128, 3)
valY shape:  (1616, 4)
[INFO] compiling model...
Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #
=================================================================
 mobilenet_1.00_128 (Functio  (None, 4, 4, 1024)       3228864
 nal)

 global_average_pooling2d (G  (None, 1024)             0
 lobalAveragePooling2D)

 dropout (Dropout)           (None, 1024)              0

 flatten (Flatten)           (None, 1024)              0

 dense (Dense)               (None, 4)                 4100

=================================================================
Total params: 3,232,964
Trainable params: 4,100
Non-trainable params: 3,228,864
_________________________________________________________________
None
bat dau fit model MobileNet
2023-11-05 13:49:05.716164: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1270874112 exceeds 10% of free system memory.
Epoch 1/32
2023-11-05 13:49:10.671168: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.34GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.
201/202 [============================>.] - ETA: 0s - loss: 0.1898 - accuracy: 0.93452023-11-05 13:49:21.891585: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.30GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.
202/202 [==============================] - 16s 56ms/step - loss: 0.1891 - accuracy: 0.9347 - val_loss: 0.0040 - val_accuracy: 1.0000
Epoch 2/32
202/202 [==============================] - 10s 50ms/step - loss: 0.0179 - accuracy: 0.9964 - val_loss: 0.0018 - val_accuracy: 1.0000
Epoch 3/32
202/202 [==============================] - 10s 50ms/step - loss: 0.0107 - accuracy: 0.9978 - val_loss: 9.4678e-04 - val_accuracy: 1.0000
Epoch 4/32
202/202 [==============================] - 10s 50ms/step - loss: 0.0065 - accuracy: 0.9991 - val_loss: 7.4946e-04 - val_accuracy: 1.0000
Epoch 5/32
202/202 [==============================] - 10s 50ms/step - loss: 0.0078 - accuracy: 0.9985 - val_loss: 7.5625e-04 - val_accuracy: 1.0000
Epoch 6/32
202/202 [==============================] - 10s 50ms/step - loss: 0.0041 - accuracy: 0.9994 - val_loss: 3.7645e-04 - val_accuracy: 1.0000
Epoch 7/32
202/202 [==============================] - 10s 50ms/step - loss: 0.0044 - accuracy: 0.9986 - val_loss: 3.8476e-04 - val_accuracy: 1.0000
Epoch 8/32
202/202 [==============================] - 10s 50ms/step - loss: 0.0041 - accuracy: 0.9989 - val_loss: 2.2977e-04 - val_accuracy: 1.0000
Epoch 9/32
202/202 [==============================] - 10s 50ms/step - loss: 0.0042 - accuracy: 0.9991 - val_loss: 6.3019e-04 - val_accuracy: 1.0000
Epoch 10/32
202/202 [==============================] - 10s 50ms/step - loss: 0.0032 - accuracy: 0.9995 - val_loss: 5.8811e-04 - val_accuracy: 1.0000
Epoch 11/32
202/202 [==============================] - 10s 50ms/step - loss: 0.0017 - accuracy: 0.9997 - val_loss: 6.5146e-04 - val_accuracy: 1.0000
Epoch 12/32
202/202 [==============================] - 10s 50ms/step - loss: 0.0034 - accuracy: 0.9992 - val_loss: 9.1333e-04 - val_accuracy: 1.0000
Epoch 13/32
202/202 [==============================] - 10s 50ms/step - loss: 0.0028 - accuracy: 0.9991 - val_loss: 5.4530e-04 - val_accuracy: 1.0000
Epoch 14/32
202/202 [==============================] - 10s 51ms/step - loss: 0.0024 - accuracy: 0.9991 - val_loss: 1.5692e-04 - val_accuracy: 1.0000
Epoch 15/32
202/202 [==============================] - 10s 51ms/step - loss: 0.0033 - accuracy: 0.9992 - val_loss: 1.8503e-04 - val_accuracy: 1.0000
Epoch 16/32
202/202 [==============================] - 10s 51ms/step - loss: 0.0031 - accuracy: 0.9992 - val_loss: 1.7190e-04 - val_accuracy: 1.0000
Epoch 17/32
202/202 [==============================] - 10s 51ms/step - loss: 0.0028 - accuracy: 0.9992 - val_loss: 6.0894e-04 - val_accuracy: 1.0000
Epoch 18/32
202/202 [==============================] - 10s 51ms/step - loss: 0.0028 - accuracy: 0.9995 - val_loss: 0.0013 - val_accuracy: 0.9988
Epoch 19/32
202/202 [==============================] - 10s 51ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 2.4273e-04 - val_accuracy: 1.0000
Epoch 20/32
202/202 [==============================] - 10s 51ms/step - loss: 7.8000e-04 - accuracy: 0.9998 - val_loss: 1.7042e-04 - val_accuracy: 1.0000
Epoch 21/32
202/202 [==============================] - 10s 50ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 2.7840e-04 - val_accuracy: 1.0000
Epoch 22/32
202/202 [==============================] - 10s 50ms/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 9.6873e-05 - val_accuracy: 1.0000
Epoch 23/32
202/202 [==============================] - 10s 51ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 1.3226e-04 - val_accuracy: 1.0000
Epoch 24/32
202/202 [==============================] - 10s 50ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 1.0847e-04 - val_accuracy: 1.0000
Epoch 25/32
202/202 [==============================] - 10s 50ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 2.2844e-04 - val_accuracy: 1.0000
Epoch 26/32
202/202 [==============================] - 10s 50ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.0025 - val_accuracy: 0.9988
Epoch 27/32
202/202 [==============================] - 11s 52ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 4.8455e-05 - val_accuracy: 1.0000
Epoch 28/32
202/202 [==============================] - 10s 50ms/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 4.3229e-05 - val_accuracy: 1.0000
Epoch 29/32
202/202 [==============================] - 10s 50ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 2.0151e-04 - val_accuracy: 1.0000
Epoch 30/32
202/202 [==============================] - 10s 51ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 5.4619e-05 - val_accuracy: 1.0000
Epoch 31/32
202/202 [==============================] - 10s 51ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 2.1718e-04 - val_accuracy: 1.0000
Epoch 32/32
202/202 [==============================] - 10s 50ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 1.0244e-04 - val_accuracy: 1.0000
new_model:   <keras.engine.sequential.Sequential object at 0x0000020DA00EAA90>
prepare save new_model:
bat dau kiem tra model:
63/64 [============================>.] - ETA: 0s2023-11-05 13:54:59.894081: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.15GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.
2023-11-05 13:54:59.911043: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.28GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.
64/64 [==============================] - 3s 41ms/step
E:\CTU\LUAN_VAN_2023\train_pose_mobileNet_beta.py:152: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels([''] + categories)
E:\CTU\LUAN_VAN_2023\train_pose_mobileNet_beta.py:153: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels([''] + categories)
Accuracy : 99.95%


Recall :99.95%


Precision : 99.95%


F1 : 99.95%


Time train MobileNet:  5.54

E:\CTU\LUAN_VAN_2023>
