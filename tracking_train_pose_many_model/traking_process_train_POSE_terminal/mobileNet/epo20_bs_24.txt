
E:\CTU\LUAN_VAN_2023>python train_pose_mobileNet_beta.py
[['./data_cropped/at_home/lie/lie_wake_530.jpg', 0], ['./data_cropped/at_home/lie/lie_wake_1206.jpg', 0], ['./data_cropped/at_home/minus/item_1479.jpg', 3], ['./data_cropped/at_home/minus/item_904.jpg', 3], ['./data_cropped/at_home/lie/lie_wake_2253.jpg', 0], ['./data_cropped/at_home/sit/sit_1798.jpg', 1], ['./data_cropped/at_home/lie/lie_wake_2056.jpg', 0], ['./data_cropped/at_home/stand/stand_1816.jpg', 2], ['./data_cropped/at_home/lie/lie_wake_1016.jpg', 0], ['./data_cropped/at_home/sit/sit_2064.jpg', 1]]
Chuan bi doc anh tu folder:
scale raw pixel / 255.0
train test split
trainX shape:  (6464, 128, 128, 3)
testX shape:  (2020, 128, 128, 3)
trainY shape:  (6464, 4)
testY shape:  (2020,)
valX shape:  (1616, 128, 128, 3)
valY shape:  (1616, 4)
[INFO] compiling model...
Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #
=================================================================
 mobilenet_1.00_128 (Functio  (None, 4, 4, 1024)       3228864
 nal)

 global_average_pooling2d (G  (None, 1024)             0
 lobalAveragePooling2D)

 dropout (Dropout)           (None, 1024)              0

 flatten (Flatten)           (None, 1024)              0

 dense (Dense)               (None, 4)                 4100

=================================================================
Total params: 3,232,964
Trainable params: 4,100
Non-trainable params: 3,228,864
_________________________________________________________________
None
bat dau fit model MobileNet
2023-11-05 12:44:46.148695: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1270874112 exceeds 10% of free system memory.
Epoch 1/20
2023-11-05 12:44:50.789713: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.32GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.
269/270 [============================>.] - ETA: 0s - loss: 0.2559 - accuracy: 0.91982023-11-05 12:45:00.021554: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.29GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.
270/270 [==============================] - 17s 47ms/step - loss: 0.2556 - accuracy: 0.9199 - val_loss: 0.0089 - val_accuracy: 0.9994
Epoch 2/20
270/270 [==============================] - 11s 42ms/step - loss: 0.0186 - accuracy: 0.9952 - val_loss: 0.0056 - val_accuracy: 0.9994
Epoch 3/20
270/270 [==============================] - 11s 42ms/step - loss: 0.0098 - accuracy: 0.9983 - val_loss: 0.0048 - val_accuracy: 0.9994
Epoch 4/20
270/270 [==============================] - 11s 42ms/step - loss: 0.0073 - accuracy: 0.9991 - val_loss: 0.0045 - val_accuracy: 0.9994
Epoch 5/20
270/270 [==============================] - 11s 42ms/step - loss: 0.0064 - accuracy: 0.9986 - val_loss: 0.0035 - val_accuracy: 0.9994
Epoch 6/20
270/270 [==============================] - 11s 42ms/step - loss: 0.0058 - accuracy: 0.9989 - val_loss: 0.0041 - val_accuracy: 0.9994
Epoch 7/20
270/270 [==============================] - 11s 42ms/step - loss: 0.0051 - accuracy: 0.9991 - val_loss: 0.0047 - val_accuracy: 0.9994
Epoch 8/20
270/270 [==============================] - 11s 42ms/step - loss: 0.0041 - accuracy: 0.9994 - val_loss: 0.0038 - val_accuracy: 0.9994
Epoch 9/20
270/270 [==============================] - 11s 41ms/step - loss: 0.0034 - accuracy: 0.9992 - val_loss: 0.0046 - val_accuracy: 0.9994
Epoch 10/20
270/270 [==============================] - 11s 42ms/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 0.0044 - val_accuracy: 0.9994
Epoch 11/20
270/270 [==============================] - 11s 42ms/step - loss: 0.0029 - accuracy: 0.9992 - val_loss: 0.0041 - val_accuracy: 0.9994
Epoch 12/20
270/270 [==============================] - 11s 42ms/step - loss: 0.0033 - accuracy: 0.9989 - val_loss: 0.0025 - val_accuracy: 0.9994
Epoch 13/20
270/270 [==============================] - 11s 42ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.0049 - val_accuracy: 0.9994
Epoch 14/20
270/270 [==============================] - 11s 42ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.0033 - val_accuracy: 0.9994
Epoch 15/20
270/270 [==============================] - 11s 42ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.0046 - val_accuracy: 0.9994
Epoch 16/20
270/270 [==============================] - 11s 42ms/step - loss: 9.0820e-04 - accuracy: 0.9998 - val_loss: 0.0024 - val_accuracy: 0.9994
Epoch 17/20
270/270 [==============================] - 11s 42ms/step - loss: 7.9017e-04 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9994
Epoch 18/20
270/270 [==============================] - 11s 42ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.0046 - val_accuracy: 0.9994
Epoch 19/20
270/270 [==============================] - 11s 42ms/step - loss: 4.4537e-04 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 0.9994
Epoch 20/20
270/270 [==============================] - 11s 41ms/step - loss: 8.5134e-04 - accuracy: 0.9998 - val_loss: 0.0048 - val_accuracy: 0.9994
new_model:   <keras.engine.sequential.Sequential object at 0x00000253D55FB940>
prepare save new_model:
bat dau kiem tra model:
2023-11-05 12:48:49.686669: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.18GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.
2023-11-05 12:48:49.708731: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.34GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.
63/64 [============================>.] - ETA: 0s2023-11-05 12:48:52.187200: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.15GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.
2023-11-05 12:48:52.204391: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.28GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.
64/64 [==============================] - 4s 40ms/step
E:\CTU\LUAN_VAN_2023\train_pose_mobileNet_beta.py:152: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels([''] + categories)
E:\CTU\LUAN_VAN_2023\train_pose_mobileNet_beta.py:153: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels([''] + categories)
Accuracy : 100.00%


Recall :100.00%


Precision : 100.00%


F1 : 100.00%


Time train MobileNet:  3.87

E:\CTU\LUAN_VAN_2023>
