
E:\CTU\LUAN_VAN_2023>python train_pose_denseNet121_beta.py
[['./data_cropped/at_home/minus/item_1829.jpg', 3], ['./data_cropped/at_home/stand/stand_707.jpg', 2], ['./data_cropped/at_home/lie/lie_wake_2350.jpg', 0],['./data_cropped/at_home/lie/lie_wake_2479.jpg', 0], ['./data_cropped/at_home/minus/item_2023.jpg', 3], ['./data_cropped/at_home/stand/stand_1897.jpg', 2],['./data_cropped/at_home/minus/item_1842.jpg', 3], ['./data_cropped/at_home/lie/lie_wake_328.jpg', 0], ['./data_cropped/at_home/minus/item_2081.jpg', 3], ['./data_cropped/at_home/sit/sit_159.jpg', 1]]
Chuan bi doc anh tu folder:
scale raw pixel / 255.0
train test split
trainX shape:  (6464, 128, 128, 3)
testX shape:  (2020, 128, 128, 3)
trainY shape:  (6464, 4)
testY shape:  (2020,)
valX shape:  (1616, 128, 128, 3)
valY shape:  (1616, 4)
[INFO] compiling model...
Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #
=================================================================
 densenet121 (Functional)    (None, 4, 4, 1024)        7037504

 global_average_pooling2d (G  (None, 1024)             0
 lobalAveragePooling2D)

 dropout (Dropout)           (None, 1024)              0

 flatten (Flatten)           (None, 1024)              0

 dense (Dense)               (None, 4)                 4100

=================================================================
Total params: 7,041,604
Trainable params: 4,100
Non-trainable params: 7,037,504
_________________________________________________________________
None
bat dau fit model DenseNet121
2023-11-17 15:39:37.840308: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1270874112 exceeds 10% of free system memory.
Epoch 1/54
101/101 [==============================] - ETA: 0s - loss: 0.6208 - accuracy: 0.79492023-11-17 15:40:12.617443: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.18GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.
101/101 [==============================] - 35s 240ms/step - loss: 0.6208 - accuracy: 0.7949 - val_loss: 0.0311 - val_accuracy: 0.9944
Epoch 2/54
101/101 [==============================] - 20s 200ms/step - loss: 0.0835 - accuracy: 0.9748 - val_loss: 0.0140 - val_accuracy: 0.9988
Epoch 3/54
101/101 [==============================] - 20s 198ms/step - loss: 0.0533 - accuracy: 0.9873 - val_loss: 0.0114 - val_accuracy: 0.9988
Epoch 4/54
101/101 [==============================] - 20s 199ms/step - loss: 0.0385 - accuracy: 0.9882 - val_loss: 0.0079 - val_accuracy: 0.9994
Epoch 5/54
101/101 [==============================] - 20s 198ms/step - loss: 0.0298 - accuracy: 0.9915 - val_loss: 0.0063 - val_accuracy: 0.9994
Epoch 6/54
101/101 [==============================] - 20s 200ms/step - loss: 0.0223 - accuracy: 0.9963 - val_loss: 0.0053 - val_accuracy: 0.9994
Epoch 7/54
101/101 [==============================] - 20s 197ms/step - loss: 0.0225 - accuracy: 0.9941 - val_loss: 0.0052 - val_accuracy: 0.9994
Epoch 8/54
101/101 [==============================] - 20s 197ms/step - loss: 0.0196 - accuracy: 0.9946 - val_loss: 0.0051 - val_accuracy: 0.9994
Epoch 9/54
101/101 [==============================] - 20s 198ms/step - loss: 0.0172 - accuracy: 0.9958 - val_loss: 0.0039 - val_accuracy: 0.9994
Epoch 10/54
101/101 [==============================] - 20s 198ms/step - loss: 0.0157 - accuracy: 0.9968 - val_loss: 0.0044 - val_accuracy: 0.9994
new_model:   <keras.engine.sequential.Sequential object at 0x000001D08BFCDC40>
prepare save new_model:
bat dau kiem tra model:
2023-11-17 15:43:17.957045: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.21GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.
63/64 [============================>.] - ETA: 0s2023-11-17 15:43:25.119356: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.15GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.
64/64 [==============================] - 11s 113ms/step
E:\CTU\LUAN_VAN_2023\train_pose_denseNet121_beta.py:156: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels([''] + categories)
E:\CTU\LUAN_VAN_2023\train_pose_denseNet121_beta.py:157: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels([''] + categories)
Accuracy: 100.0
F1 Score: 100.0
Recall: 100.0
Precision: 100.0
Time train DenseNet121:  3.6
Time predict DenseNet121:  0.2

E:\CTU\LUAN_VAN_2023>
