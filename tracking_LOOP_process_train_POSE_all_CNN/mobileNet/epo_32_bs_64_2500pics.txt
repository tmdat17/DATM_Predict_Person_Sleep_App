
E:\CTU\LUAN_VAN_2023>python train_pose_mobileNet_beta.py
[['./data_cropped/at_home/sit/sit_2153.jpg', 1], ['./data_cropped/at_home/lie/lie_wake_508.jpg', 0], ['./data_cropped/at_home/minus/item_2116.jpg', 3], ['./data_cropped/at_home/sit/sit_989.jpg', 1], ['./data_cropped/at_home/sit/sit_537.jpg', 1], ['./data_cropped/at_home/stand/stand_2141.jpg', 2], ['./data_cropped/at_home/minus/item_2026.jpg', 3], ['./data_cropped/at_home/minus/item_1847.jpg', 3], ['./data_cropped/at_home/minus/item_1786.jpg', 3], ['./data_cropped/at_home/stand/stand_2232.jpg', 2]]
Chuan bi doc anh tu folder:
scale raw pixel / 255.0
train test split
trainX shape:  (6464, 128, 128, 3)
testX shape:  (2020, 128, 128, 3)
trainY shape:  (6464, 4)
testY shape:  (2020,)
valX shape:  (1616, 128, 128, 3)
valY shape:  (1616, 4)
[INFO] compiling model...
Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #
=================================================================
 mobilenet_1.00_128 (Functio  (None, 4, 4, 1024)       3228864
 nal)

 global_average_pooling2d (G  (None, 1024)             0
 lobalAveragePooling2D)

 dropout (Dropout)           (None, 1024)              0

 flatten (Flatten)           (None, 1024)              0

 dense (Dense)               (None, 4)                 4100

=================================================================
Total params: 3,232,964
Trainable params: 4,100
Non-trainable params: 3,228,864
_________________________________________________________________
None
bat dau fit model MobileNet
2023-11-24 08:19:15.780675: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1270874112 exceeds 10% of free system memory.
Epoch 1/32
2023-11-24 08:19:20.144398: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.41GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.
101/101 [==============================] - ETA: 0s - loss: 0.4313 - accuracy: 0.85232023-11-24 08:19:30.076573: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.30GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.
101/101 [==============================] - 14s 99ms/step - loss: 0.4313 - accuracy: 0.8523 - val_loss: 0.0156 - val_accuracy: 0.9988
Epoch 2/32
101/101 [==============================] - 9s 86ms/step - loss: 0.0356 - accuracy: 0.9923 - val_loss: 0.0090 - val_accuracy: 0.9994
Epoch 3/32
101/101 [==============================] - 9s 86ms/step - loss: 0.0189 - accuracy: 0.9971 - val_loss: 0.0072 - val_accuracy: 0.9994
Epoch 4/32
101/101 [==============================] - 9s 86ms/step - loss: 0.0128 - accuracy: 0.9980 - val_loss: 0.0063 - val_accuracy: 0.9994
Epoch 5/32
101/101 [==============================] - 9s 86ms/step - loss: 0.0099 - accuracy: 0.9986 - val_loss: 0.0054 - val_accuracy: 0.9994
Epoch 6/32
101/101 [==============================] - 9s 86ms/step - loss: 0.0071 - accuracy: 0.9985 - val_loss: 0.0049 - val_accuracy: 0.9994
Epoch 7/32
101/101 [==============================] - 9s 87ms/step - loss: 0.0076 - accuracy: 0.9988 - val_loss: 0.0045 - val_accuracy: 0.9994
Epoch 8/32
101/101 [==============================] - 9s 86ms/step - loss: 0.0055 - accuracy: 0.9995 - val_loss: 0.0037 - val_accuracy: 0.9994
new_model:   <keras.engine.sequential.Sequential object at 0x0000026CBFB8DA30>
prepare save new_model:
bat dau kiem tra model:
2023-11-24 08:20:32.170690: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.18GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.
2023-11-24 08:20:32.192666: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.34GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.
63/64 [============================>.] - ETA: 0s2023-11-24 08:20:34.650459: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.15GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.
2023-11-24 08:20:34.668838: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.28GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.
64/64 [==============================] - 3s 39ms/step
Accuracy: 99.9009900990099
F1 Score: 99.90393852065321
Recall: 99.80806142034548
Precision: 100.0
Time train mobileNet:  1.26
Time predict mobileNet:  0.06

E:\CTU\LUAN_VAN_2023>
