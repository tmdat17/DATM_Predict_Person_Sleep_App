
E:\CTU\LUAN_VAN_2023>python train_pose_inceptionV3_beta.py
[['./data_cropped/at_home/minus/item_735.jpg', 3], ['./data_cropped/at_home/stand/stand_230.jpg', 2], ['./data_cropped/at_home/lie/lie_wake_1691.jpg', 0], ['./data_cropped/at_home/minus/item_284.jpg', 3], ['./data_cropped/at_home/sit/sit_723.jpg', 1], ['./data_cropped/at_home/minus/item_1845.jpg', 3], ['./data_cropped/at_home/sit/sit_1777.jpg', 1], ['./data_cropped/at_home/lie/lie_wake_1325.jpg', 0], ['./data_cropped/at_home/minus/item_190.jpg', 3], ['./data_cropped/at_home/minus/item_2452.jpg', 3]]
Chuan bi doc anh tu folder:
scale raw pixel / 255.0
train test split
trainX shape:  (6464, 128, 128, 3)
testX shape:  (2020, 128, 128, 3)
trainY shape:  (6464, 4)
testY shape:  (2020,)
valX shape:  (1616, 128, 128, 3)
valY shape:  (1616, 4)
[INFO] compiling model...
Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #
=================================================================
 inception_v3 (Functional)   (None, 2, 2, 2048)        21802784

 global_average_pooling2d (G  (None, 2048)             0
 lobalAveragePooling2D)

 dropout (Dropout)           (None, 2048)              0

 flatten (Flatten)           (None, 2048)              0

 dense (Dense)               (None, 4)                 8196

=================================================================
Total params: 21,810,980
Trainable params: 8,196
Non-trainable params: 21,802,784
_________________________________________________________________
None
bat dau fit model InceptionV3
2023-11-17 16:33:01.705695: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1270874112 exceeds 10% of free system memory.
Epoch 1/20
2023-11-17 16:33:09.604404: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.53GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.
2023-11-17 16:33:09.623389: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.81GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.
2023-11-17 16:33:09.642475: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.09GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.
269/270 [============================>.] - ETA: 0s - loss: 0.2640 - accuracy: 0.92082023-11-17 16:33:28.334666: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.46GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.
2023-11-17 16:33:28.352224: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.74GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.
2023-11-17 16:33:28.369267: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.02GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.
270/270 [==============================] - 32s 93ms/step - loss: 0.2641 - accuracy: 0.9208 - val_loss: 0.0075 - val_accuracy: 0.9981
Epoch 2/20
270/270 [==============================] - 22s 81ms/step - loss: 0.0473 - accuracy: 0.9855 - val_loss: 0.0036 - val_accuracy: 0.9988
Epoch 3/20
270/270 [==============================] - 22s 82ms/step - loss: 0.0258 - accuracy: 0.9915 - val_loss: 0.0039 - val_accuracy: 0.9994
Epoch 4/20
270/270 [==============================] - 22s 82ms/step - loss: 0.0212 - accuracy: 0.9937 - val_loss: 0.0013 - val_accuracy: 1.0000
Epoch 5/20
270/270 [==============================] - 22s 82ms/step - loss: 0.0234 - accuracy: 0.9930 - val_loss: 9.5762e-04 - val_accuracy: 1.0000
Epoch 6/20
270/270 [==============================] - 22s 82ms/step - loss: 0.0197 - accuracy: 0.9944 - val_loss: 0.0046 - val_accuracy: 0.9981
Epoch 7/20
270/270 [==============================] - 22s 82ms/step - loss: 0.0104 - accuracy: 0.9966 - val_loss: 0.0013 - val_accuracy: 1.0000
Epoch 8/20
270/270 [==============================] - 22s 82ms/step - loss: 0.0059 - accuracy: 0.9978 - val_loss: 0.0037 - val_accuracy: 0.9988
Epoch 9/20
270/270 [==============================] - 22s 82ms/step - loss: 0.0083 - accuracy: 0.9971 - val_loss: 2.7962e-04 - val_accuracy: 1.0000
Epoch 10/20
270/270 [==============================] - 22s 82ms/step - loss: 0.0064 - accuracy: 0.9977 - val_loss: 0.0029 - val_accuracy: 0.9988
new_model:   <keras.engine.sequential.Sequential object at 0x00000218BAAE4670>
prepare save new_model:
bat dau kiem tra model:
2023-11-17 16:36:57.519962: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1007.56MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.
2023-11-17 16:36:57.535510: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.16GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.
2023-11-17 16:36:57.551666: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.34GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.
2023-11-17 16:36:57.673420: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 840.50MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.
64/64 [==============================] - 8s 78ms/step
E:\CTU\LUAN_VAN_2023\train_pose_inceptionV3_beta.py:156: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels([''] + categories)
E:\CTU\LUAN_VAN_2023\train_pose_inceptionV3_beta.py:157: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels([''] + categories)
Accuracy: 99.65346534653466
F1 Score: 99.8974358974359
Recall: 99.79508196721312
Precision: 100.0
Time train InceptionV3:  3.88
Time predict InceptionV3:  0.14

E:\CTU\LUAN_VAN_2023>
