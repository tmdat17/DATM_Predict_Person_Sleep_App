
E:\CTU\LUAN_VAN_2023>python train_pose_inceptionV3_beta.py
[['./data_cropped/at_home/lie/lie_wake_2497.jpg', 0], ['./data_cropped/at_home/minus/item_2266.jpg', 3], ['./data_cropped/at_home/lie/lie_wake_1233.jpg', 0], ['./data_cropped/at_home/stand/stand_2028.jpg', 2], ['./data_cropped/at_home/minus/item_1077.jpg', 3], ['./data_cropped/at_home/lie/lie_wake_1417.jpg', 0], ['./data_cropped/at_home/stand/stand_1532.jpg', 2], ['./data_cropped/at_home/lie/lie_wake_2362.jpg', 0], ['./data_cropped/at_home/minus/item_2265.jpg', 3], ['./data_cropped/at_home/lie/lie_wake_2240.jpg', 0]]
Chuan bi doc anh tu folder:
scale raw pixel / 255.0
train test split
trainX shape:  (6464, 128, 128, 3)
testX shape:  (2020, 128, 128, 3)
trainY shape:  (6464, 4)
testY shape:  (2020,)
valX shape:  (1616, 128, 128, 3)
valY shape:  (1616, 4)
[INFO] compiling model...
Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #
=================================================================
 inception_v3 (Functional)   (None, 2, 2, 2048)        21802784

 global_average_pooling2d (G  (None, 2048)             0
 lobalAveragePooling2D)

 dropout (Dropout)           (None, 2048)              0

 flatten (Flatten)           (None, 2048)              0

 dense (Dense)               (None, 4)                 8196

=================================================================
Total params: 21,810,980
Trainable params: 8,196
Non-trainable params: 21,802,784
_________________________________________________________________
None
bat dau fit model InceptionV3
2023-11-17 16:45:04.563236: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1270874112 exceeds 10% of free system memory.
Epoch 1/20
2023-11-17 16:45:12.663224: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.42GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.
2023-11-17 16:45:12.856064: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.71GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.
2023-11-17 16:45:12.876355: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.99GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.
2023-11-17 16:45:12.899106: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.27GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.
101/101 [==============================] - ETA: 0s - loss: 0.3887 - accuracy: 0.88692023-11-17 16:45:29.415322: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.29GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.
2023-11-17 16:45:29.553786: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.49GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.
2023-11-17 16:45:29.571780: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.78GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.
2023-11-17 16:45:29.591455: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.06GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.
101/101 [==============================] - 24s 167ms/step - loss: 0.3887 - accuracy: 0.8869 - val_loss: 0.0278 - val_accuracy: 0.9926
Epoch 2/20
101/101 [==============================] - 14s 138ms/step - loss: 0.0573 - accuracy: 0.9833 - val_loss: 0.0145 - val_accuracy: 0.9969
Epoch 3/20
101/101 [==============================] - 14s 138ms/step - loss: 0.0398 - accuracy: 0.9879 - val_loss: 0.0109 - val_accuracy: 0.9963
Epoch 4/20
101/101 [==============================] - 14s 137ms/step - loss: 0.0275 - accuracy: 0.9912 - val_loss: 0.0096 - val_accuracy: 0.9969
Epoch 5/20
101/101 [==============================] - 14s 137ms/step - loss: 0.0204 - accuracy: 0.9935 - val_loss: 0.0092 - val_accuracy: 0.9975
Epoch 6/20
101/101 [==============================] - 14s 137ms/step - loss: 0.0191 - accuracy: 0.9940 - val_loss: 0.0065 - val_accuracy: 0.9981
Epoch 7/20
101/101 [==============================] - 14s 137ms/step - loss: 0.0118 - accuracy: 0.9963 - val_loss: 0.0065 - val_accuracy: 0.9975
Epoch 8/20
101/101 [==============================] - 14s 138ms/step - loss: 0.0131 - accuracy: 0.9949 - val_loss: 0.0073 - val_accuracy: 0.9988
Epoch 9/20
101/101 [==============================] - 14s 137ms/step - loss: 0.0095 - accuracy: 0.9964 - val_loss: 0.0051 - val_accuracy: 0.9981
Epoch 10/20
101/101 [==============================] - 14s 137ms/step - loss: 0.0086 - accuracy: 0.9972 - val_loss: 0.0051 - val_accuracy: 0.9988
Epoch 11/20
101/101 [==============================] - 14s 137ms/step - loss: 0.0078 - accuracy: 0.9972 - val_loss: 0.0092 - val_accuracy: 0.9975
Epoch 12/20
101/101 [==============================] - 14s 136ms/step - loss: 0.0089 - accuracy: 0.9968 - val_loss: 0.0054 - val_accuracy: 0.9969
Epoch 13/20
101/101 [==============================] - 14s 136ms/step - loss: 0.0083 - accuracy: 0.9972 - val_loss: 0.0059 - val_accuracy: 0.9969
Epoch 14/20
101/101 [==============================] - 14s 137ms/step - loss: 0.0077 - accuracy: 0.9972 - val_loss: 0.0044 - val_accuracy: 0.9981
new_model:   <keras.engine.sequential.Sequential object at 0x000001E947274A30>
prepare save new_model:
bat dau kiem tra model:
2023-11-17 16:48:32.630666: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1007.56MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.
2023-11-17 16:48:32.646680: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.16GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.
64/64 [==============================] - 8s 79ms/step
E:\CTU\LUAN_VAN_2023\train_pose_inceptionV3_beta.py:156: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels([''] + categories)
E:\CTU\LUAN_VAN_2023\train_pose_inceptionV3_beta.py:157: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels([''] + categories)
Accuracy: 99.65346534653466
F1 Score: 99.69543147208122
Recall: 99.59432048681542
Precision: 99.79674796747967
Time train InceptionV3:  3.42
Time predict InceptionV3:  0.14

E:\CTU\LUAN_VAN_2023>
